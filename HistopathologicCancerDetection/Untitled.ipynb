{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.densenet import DenseNet121, DenseNet201\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPooling2D, Concatenate, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **本地用matplotlib绘图可以，但是在Linux服务器运行代码绘图的时候会报错，需要添加这行代码**\n",
    "# plt.switch_backend('agg')\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2,3,4'\n",
    "\n",
    "train_dir = 'data/train/'\n",
    "\n",
    "IMG_SIZE = (96, 96)\n",
    "IN_SHAPE = (96, 96, 3)\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "def load_data(train, valid):\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=lambda x: (x - x.mean()) / x.std() if x.std() > 0 else x,\n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True)\n",
    "\n",
    "    valid_datagen = ImageDataGenerator(preprocessing_function=lambda x: (\n",
    "        x - x.mean()) / x.std() if x.std() > 0 else x)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train,\n",
    "        directory=train_dir,\n",
    "        x_col='id',\n",
    "        y_col='label',\n",
    "        has_ext=False,\n",
    "        # subset='training',\n",
    "        batch_size=8,\n",
    "        seed=2019,\n",
    "        shuffle=True,\n",
    "        class_mode='binary',\n",
    "        target_size=IMG_SIZE)\n",
    "\n",
    "    valid_generator = valid_datagen.flow_from_dataframe(\n",
    "        dataframe=valid,\n",
    "        directory=train_dir,\n",
    "        x_col='id',\n",
    "        y_col='label',\n",
    "        has_ext=False,\n",
    "        # subset='validation',\n",
    "        batch_size=8,\n",
    "        seed=2019,\n",
    "        shuffle=False,\n",
    "        class_mode='binary',\n",
    "        target_size=IMG_SIZE\n",
    "    )\n",
    "    print(len(train_generator))\n",
    "    return train_generator, valid_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_bulid():\n",
    "    inputs = Input(IN_SHAPE)\n",
    "    conv_base = DenseNet201(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=IN_SHAPE\n",
    "    )\n",
    "    x = conv_base(inputs)\n",
    "    out = Flatten()(x)\n",
    "    # **如果换成256验证集效果很差，我也不知道为什么**\n",
    "    out = Dense(512)(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation(activation='relu')(out)\n",
    "    out = Dropout(dropout_rate)(out)\n",
    "    out = Dense(1, activation=\"sigmoid\", name=\"3_\")(out)\n",
    "    model = Model(inputs, out)\n",
    "\n",
    "    conv_base.Trainable = True\n",
    "    set_trainable = False\n",
    "    for layer in conv_base.layers:\n",
    "        if layer.name == 'res5a_branch2a':\n",
    "            set_trainable = True\n",
    "        if set_trainable:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "\n",
    "    model.compile(Adam(),\n",
    "                  loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    model.summary()\n",
    "#     plot_model(model, to_file='NetStruct.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         id label\n",
      "0  1baf53d98f7d4721e3a491011cb2bf2463c5d29b     0\n",
      "1  e9644bfb5f3072d3038e9ad74f0cf741af690581     1\n",
      "2  31234755b94e3e4ac916b8ce2242b5719c8ba403     1\n",
      "3  86abd7205c7e5cef8fef44d530c9785850e3062b     1\n",
      "4  97c5c61a5ab8223b0fb42b69f2ac24e02d5b4416     0\n",
      "                                         id label\n",
      "0  7653fda2957b0831b28c78d18e64637ae2bd44d9     0\n",
      "1  7232ca54dbc27c520410046caf97544d2ecff0bd     1\n",
      "2  edf83f14fdec3b12d1c084b0d21fc2d384589631     0\n",
      "3  3fdb04c3b6f555e14660b5f21fe0fe69b1ff5f35     1\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Start KFold number 1 from 5\n",
      "Split train:  0\n",
      "Split valid:  0\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "densenet201 (Model)          (None, 3, 3, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 17280)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               8847872   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "3_ (Dense)                   (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 27,172,417\n",
      "Trainable params: 8,849,409\n",
      "Non-trainable params: 18,323,008\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "\n",
    "    nfolds = 5\n",
    "    epoch = 30\n",
    "    random_state = 2019\n",
    "\n",
    "    df_train = pd.read_csv('data/train_labels.csv')\n",
    "    df_train = df_train.sample(n=20, random_state=random_state)\n",
    "    df_train = df_train.values\n",
    "    kf = KFold(n_splits=nfolds,\n",
    "               shuffle=True, random_state=random_state)\n",
    "    num_fold = 0\n",
    "    for train_index, valid_index in kf.split(df_train):\n",
    "        \n",
    "        train_df, valid_df = df_train[train_index], df_train[valid_index]\n",
    "        train_df = pd.DataFrame(train_df, columns=['id', 'label']).astype('str')\n",
    "        valid_df = pd.DataFrame(valid_df, columns=['id', 'label']).astype('str')\n",
    "        print(train_df.head())\n",
    "        print(valid_df.head())\n",
    "        train, valid = load_data(train_df, valid_df)\n",
    "        num_fold += 1\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        print('Split train: ', len(train))\n",
    "        print('Split valid: ', len(valid))\n",
    "        model = model_bulid()\n",
    "        tensorboard = TensorBoard(log_dir='./logs_kfold',  # log 目录\n",
    "                                  # histogram_freq=1,  # 按照何等频率（epoch）来计算直方图，0为不计算\n",
    "                                  # batch_size=batch_size,     # 用多大量的数据计算直方图\n",
    "                                  write_graph=True,  # 是否存储网络结构图\n",
    "                                  write_grads=False,  # 是否可视化梯度直方图\n",
    "                                  write_images=False,  # 是否可视化参数\n",
    "                                  embeddings_freq=0,\n",
    "                                  embeddings_layer_names=None,\n",
    "                                  embeddings_metadata=None)\n",
    "        model_checkpoint = ModelCheckpoint(\n",
    "            'weights_kfold'+'_'+str(num_fold)+'.h5', monitor='val_loss', save_best_only=True)\n",
    "        earlystopper = EarlyStopping(\n",
    "            monitor='val_loss', patience=2, verbose=1)\n",
    "        reducel = ReduceLROnPlateau(\n",
    "            monitor='val_loss', patience=1, verbose=1, factor=0.1)\n",
    "\n",
    "        history = model.fit_generator(train,\n",
    "                                      validation_data=valid,\n",
    "                                      epochs=epoch,\n",
    "                                      callbacks=[reducel, earlystopper, model_checkpoint, tensorboard],\n",
    "                                      steps_per_epoch=train_df.shape[0]/8,\n",
    "                                      validation_steps=valid_df.shape[0]/8)\n",
    "\n",
    "        plt.plot(history.history['loss'], label='train')\n",
    "        plt.plot(history.history['val_loss'], label='valid')\n",
    "        plt.title(\"model loss\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.legend([\"train\", \"valid\"], loc=\"upper left\")\n",
    "        plt.savefig('loss_performance'+'_'+str(num_fold)+'.png')\n",
    "        plt.clf()\n",
    "        plt.plot(history.history['acc'], label='train')\n",
    "        plt.plot(history.history['val_acc'], label='valid')\n",
    "        plt.title(\"model acc\")\n",
    "        plt.ylabel(\"acc\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.legend([\"train\", \"valid\"], loc=\"upper left\")\n",
    "        plt.savefig('acc_performance'+'_'+str(num_fold)+'.png')\n",
    "\n",
    "        with open('logs_kfold.txt', 'a+') as f:\n",
    "            f.write(str(datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\"))+'\\n')\n",
    "            f.write(str(num_fold)+'\\n')\n",
    "            f.write(str(history.history['loss'])+'\\n')\n",
    "            f.write(str(history.history['val_loss'])+'\\n')\n",
    "            f.write(str(history.history['acc'])+'\\n')\n",
    "            f.write(str(history.history['val_acc'])+'\\n')\n",
    "\n",
    "\n",
    "train_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
